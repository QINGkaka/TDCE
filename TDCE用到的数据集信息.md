# TDCE 用到的数据集信息
在《Tabular Diffusion_2025.pdf》中，TDCE（Tabular Diffusion Counterfactual Explanations）算法针对表格数据的反事实解释任务，选取了4个涵盖金融、收入预测、教育测试等典型场景的大规模公开表格数据集，所有数据集均包含“连续特征+分类特征”，且经过统一预处理以适配扩散模型需求。


## 一、数据集核心信息总览
| 数据集名称 | 核心任务 | 样本量划分（训练/验证/测试） | 特征构成（数值特征数/分类特征数） | 关键应用场景 |
|------------|----------|-------------------------------|------------------------------------|--------------|
| **Lending Club Dataset（LCD）** | 信贷贷款决策预测 | 10,000 / 1,000 / 1,000 | 5 / 1 | 金融信贷领域，用于评估贷款相关决策（如贷款审批），分类特征为“贷款期限”（如36个月/60个月） |
| **Give Me Some Credit（GMC）** | 个人信贷风险预测 | 15,000 / 1,000 / 1,000 | 9 / 1 | 金融风控领域，用于预测个人信贷违约风险，包含收入、债务、信用历史等核心金融特征 |
| **Adult** | 年收入二分类预测 | 47,842 / 1,000 / 1,000 | 9 / 2 | 人口统计学与收入预测领域，基于年龄、职业、教育程度、婚姻状况等特征，预测个人年收入是否超过5万美元 |
| **LAW** | 法学院考试通过预测 | 5,502 / 1,000 / 1,000 | 8 / 3 | 教育评估领域，用于预测考生是否通过法学院相关测试，特征涵盖考试分数、背景信息（如学历、实习经历）等 |


## 二、数据集预处理方法
为适配TDCE的扩散模型架构（连续特征高斯扩散+分类特征Gumbel-softmax扩散），所有数据集均执行统一预处理流程：
1. **连续特征处理**：采用**标准化（Standardization）** 操作，将每个连续特征转换为均值为0、方差为1的分布，确保高斯扩散过程中噪声注入与去噪的稳定性🔶1-119、。
2. **分类特征处理**：先将原始分类特征（如“贷款期限”“职业”）转换为one-hot向量，再通过**Gumbel-softmax重参数化**转化为连续向量（公式：$\tilde{x}_{i,t}^{cat}=\frac{exp((g_i+log\overline{\pi}_{i,t})/\tau)}{\sum_{j=1}^K exp((g_j+log\overline{\pi}_{j,t})/\tau)}$，其中$g_i \sim Gumbel(0,1)$，$\tau$为温度参数），解决离散特征梯度不可导问题，支持反向过程的分类器梯度引导🔶1-82、🔶1-85、🔶1-119、。
3. **不可变特征处理**：通过二进制掩码$m$标记不可修改的特征（如用户固定属性），在反事实生成过程中仅更新可变特征，保留不可变特征的原始值，避免生成不符合现实逻辑的样本🔶1-108、🔶1-113、。


## 三、数据集获取途径
论文未直接提供数据集下载链接，但根据实验设计（使用CARLA库实现基线方法）及数据集公开属性，可通过以下途径获取，确保与实验数据一致性：
1. **通过CARLA库直接加载**：论文明确提到，所有基线方法（如CCHVAE、REVISE、FACE）均通过CARLA库（Python反事实解释算法基准测试库）实现，而CARLA库已内置**LCD、GMC、Adult**三个数据集，可通过调用库的`data_loader`模块直接加载预处理后的样本，无需手动处理数据格式🔶1-125、。
2. **公开数据集平台补充**：
   - **LAW数据集**：作为表格数据反事实解释领域的常用基准集，可通过教育类公开数据集平台或学术数据库（如作者所在机构哥伦比亚大学的数据集存储库）检索获取，具体需结合领域内公开资源补充🔶1-119、。
   - **Adult数据集**：也可直接从UCI机器学习仓库（UCI Machine Learning Repository）下载原始数据，再按论文预处理标准执行标准化与one-hot编码，确保与实验条件一致🔶1-119、。